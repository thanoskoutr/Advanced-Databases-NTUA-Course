# Αναφορά Εξαμηνιαίας Εργασίας

## Μάθημα
**Προχωρημένα Θέματα Βάσεων Δεδομένων**

## Θέμα
**Χρήση του Apache Spark στις Βάσεις Δεδομένων**

## Ομάδα

[Καναρόπουλος Ιωάννης Γεράσιμος](https://github.com/giannis-k) 03116016

[Κουτρούμπας Αθανάσιος](https://github.com/thanoskoutr) 03116073

## Μέρος 1ο

### Ζητούμενο 1


### Ζητούμενο 2


### Ζητούμενο 3

#### Ερώτημα Q1

#### Ερώτημα Q2

#### Ερώτημα Q3

#### Ερώτημα Q4

#### Ερώτημα Q5


### Ζητούμενο 4
Οι χρόνοι εκτέλεσεις ομαδοποιημένοι ανά ερώτημα, φαίνονται στο παρακάτω διάγραμμα:

<!-- For Exporting to PDF (absolute path) -->
<!-- ![Ραβδοδιάγραμμα-Χρόνων-Εκτέλεσης](/home/thanos/Documents/Advanced-Databases_9th-semester/src/queries_exec_times.png) -->

<!-- For Viewing in Markdown (relative path) -->
![Ραβδοδιάγραμμα-Χρόνων-Εκτέλεσης](src/queries_exec_times.png)

**Σχολιασμός Χρόνων Εκτέλεσης για κάθε ερώτημα.**
Παρατηρούμε ότι, για στα Q2, Q3 το RDD είναι πιο αργό από το αντίστοιχο query σε SQL. 
Αντίθετα στα Q1, Q4 το RDD είναι πιο γρήγορο από τα αντίστοιχα query σε SQL.

Παρατηρούμε επίσης ότι τα Q2, Q3 είναι τα πιο χρονοβόρα ανεξάρτητα τις υλοποίησης και αυτό γιατί και τα δύο χρησιμοποιούν το `ratings` αρχείο, το οποίο είναι πολύ μεγαλύτερο των άλλων αρχείων:
- `movies.csv`: 17 MB
- `movie_genres.csv`: 1.3 MB
- `ratings.csv`: 677 MB

Επίσης το Q2 χρησιμοποιεί μόνο το αρχείο `ratings`, ενώ το Q3, εφαρμόζει join πάνω στα αρχεία `ratings` και `movie_genres`, οπότε για αυτό είναι ακόμα πιο αργό.


**Τι παρατηρούμε με την χρήση του parquet;**
Για τις SQL υλοποιήσεις παρατηρούμε ότι, όταν τρέχουμε τα ερωτήματα με τα `.parquet` αρχεία έχουμε πάντα μικρότερο (έως και μισό) χρόνο εκτέλεσης σε σχέση με τα αντίστοιχα `.csv` αρχεία.
Το parquet είναι ένα columnar storage format, το οποίο είναι συμπιεσμένο άρα έχει μικρότερο αποτύπωμα στη μνήμη και στον δίσκο και βελτιστοποιεί το I/O, μειώνοντας τον χρόνο εκτέλεσης.
Επίσης διατηρεί επιπλέον πληροφορίες (metadata) για το dataset και μπορεί να διατηρήσει και το schema που μπορεί να έχουν τα δεδομένα. Οπότε είναι λογικό να έχει καλύτερες επιδόσεις από το να χρησιμοποιούμε απλά text formats όπως το CSV.


**Γιατί δεν χρησιμοποιούμε `infer schema` με την χρήση του parquet;**
Όπως αναφέραμε το parquet έχει την δυνατότητα να διατηρεί το schema των δεδομένων, οπότε όταν μετατρέψαμε στην αρχή τα `.csv` δεδομένα μας σε `.parquet` αρχεία, ορίσαμε και περάσαμε ως παράμετρο τότε το schema των δεδομένων. Αυτό το schema παρέμεινε και όταν τρέχαμε τα ερωτήμα, οπότε γλιτώσαμε και χρόνο, καθώς για το τρέξιμο στα `.csv` αρχεία, έπρεπε κάθε φορά να ορίζουμε το schema για το κάθε αρχείο-πίνακας.


## Μέρος 2o